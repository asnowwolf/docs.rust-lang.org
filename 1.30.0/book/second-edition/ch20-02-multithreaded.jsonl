{"question": "What is the problem with the current server implementation?", "answer": "The server processes each request in turn, meaning it won't process a second connection until the first is finished processing. This can lead to slow performance if a request takes a long time to process, as subsequent requests will have to wait."}
{"question": "How does the code in Listing 20-10 simulate a slow request?", "answer": "The code recognizes a request to */sleep* and simulates a slow response by sleeping for 5 seconds before responding."}
{"question": "What is a thread pool?", "answer": "A thread pool is a group of spawned threads that are waiting and ready to handle a task. When the program receives a new task, it assigns one of the threads in the pool to the task, and that thread will process the task. The remaining threads in the pool are available to handle any other tasks that come in while the first thread is processing."}
{"question": "Why is it important to limit the number of threads in a thread pool?", "answer": "Limiting the number of threads protects against Denial of Service (DoS) attacks. If the program created a new thread for each request, someone making a large number of requests could overwhelm the system by using up all the server's resources."}
{"question": "How does a thread pool handle incoming requests?", "answer": "A thread pool maintains a queue of incoming requests. Each thread in the pool pops off a request from this queue, handles the request, and then asks the queue for another request."}
{"question": "What is the benefit of using a thread pool?", "answer": "A thread pool allows you to process connections concurrently, increasing the throughput of your server."}
{"question": "What is compiler-driven development?", "answer": "Compiler-driven development involves writing the code that calls the functions you want, and then using the compiler errors to determine what changes need to be made to get the code to work."}
{"question": "What is the purpose of the `ThreadPool` struct?", "answer": "The `ThreadPool` struct is responsible for managing a pool of threads that can be used to process requests concurrently."}
{"question": "What is the purpose of the `execute` method on the `ThreadPool` struct?", "answer": "The `execute` method takes a closure and gives it to a thread in the pool to run."}
{"question": "What is the purpose of the `Worker` struct?", "answer": "The `Worker` struct is responsible for managing a single thread in the thread pool. It holds a `JoinHandle<()>` instance and a unique `id`."}
{"question": "What is the purpose of the `Job` struct?", "answer": "The `Job` struct is a type alias for a trait object that holds the type of closure that the `execute` method receives."}
{"question": "How does the `ThreadPool` struct use channels to communicate with the `Worker` structs?", "answer": "The `ThreadPool` struct creates a channel and holds the sending side of the channel. Each `Worker` struct holds the receiving side of the channel. The `execute` method sends a job down the sending side of the channel, and the `Worker` structs receive the jobs and execute them in their threads."}
{"question": "Why is it necessary to use `Arc` and `Mutex` to share the receiving end of the channel among the `Worker` structs?", "answer": "The channel implementation in Rust is multiple producer, single consumer. This means that we can't simply clone the consuming end of the channel to share it among multiple workers. Additionally, taking a job off the channel queue involves mutating the receiver, so the threads need a safe way to share and modify the receiver."}
{"question": "What is the purpose of the `FnBox` trait?", "answer": "The `FnBox` trait is a workaround for a limitation in the Rust compiler that prevents us from directly calling a `FnOnce` closure stored in a `Box<T>`. The `FnBox` trait allows us to take ownership of the closure and move it out of the `Box<T>`."}
{"question": "Why is it important to release the lock on the `Mutex` before calling `job.call_box()` in the `Worker` struct?", "answer": "If the lock is held during the call to `job.call_box()`, other workers cannot receive jobs. By releasing the lock before calling `job.call_box()`, we ensure that multiple requests can be serviced concurrently."}